{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22fda647",
   "metadata": {},
   "source": [
    "<h2><center> EEG - N. 9 </center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3391e9",
   "metadata": {},
   "source": [
    "<h3><center> MANU 465 101 </center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6294f68",
   "metadata": {},
   "source": [
    "[Set phase](#Set-phase)\n",
    "\n",
    " - [Import libraries](#Import-libraries)\n",
    " - [Setting path](#Setting-path)\n",
    "\n",
    "[Features generation](#Features-generation)\n",
    "\n",
    "\n",
    "[Import procedure](#Import-procedure)\n",
    "  - [Lists initialization](#Lists-initialization)\n",
    "  - [Final dataset creation](#Final-dataset-creation)\n",
    "       \n",
    "[Conclusions](#Conclusions)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8490606c",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Goal of the analysis: ...\n",
    "\n",
    "Data Collection: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612e1b2c",
   "metadata": {},
   "source": [
    "# Set phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3c37f3",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14256ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9e47c1",
   "metadata": {},
   "source": [
    "### Setting path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc07c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delimiter = \"\\\\\" # for windows\n",
    "delimiter = \"//\"  # for os system\n",
    "\n",
    "# add your own path:\n",
    "\n",
    "#path = r\"C:/Users/chies/OneDrive/Desktop/CLEANED DATASET- code is working/Data Collection/Unprocessed Dataset\"\n",
    "#path = r\"/Users/sofiacaltabiano/Desktop/CLEANED DATASET- code is working/Data Collection/Unprocessed Dataset\"\n",
    "path = r\"C:\\Users\\M0NYP\\Desktop\\Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c787364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928dffa1",
   "metadata": {},
   "source": [
    "Get all the filenames in the folder indicated by the previous path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3bd8e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "965a973a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c622c839",
   "metadata": {},
   "source": [
    "# Features generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c200389",
   "metadata": {},
   "source": [
    "In order to condensate each csv file in only one row, we need to use summary metrics. \n",
    "\n",
    "For each wave, which corresponds to 4 columns in each file, we want one value of mean, one value of std, and so on. Then all these values will be stored in a final dataset in a unique row that represents one csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bf80a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "def mean(x):\n",
    "    return np.mean(x, axis=0)\n",
    "def std(x):\n",
    "    return np.std(x, axis=0)\n",
    "def ptp(x):\n",
    "    return np.ptp(x, axis=0)\n",
    "def var(x):\n",
    "    return np.var(x, axis=0)\n",
    "def minim(x):\n",
    "    return np.min(x, axis=0)\n",
    "def maxim(x):\n",
    "    return np.max(x, axis=0)\n",
    "def argminim(x):\n",
    "    return np.argmin(x, axis=0)\n",
    "def argmaxim(x):\n",
    "    return np.argmax(x, axis=0)\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2, axis=0))\n",
    "def skewness(x):\n",
    "    return stats.skew(x,axis=0)\n",
    "def kurtosis(x):\n",
    "    return stats.kurtosis(x,axis=0)\n",
    "\n",
    "def concatenate_features(x):\n",
    "    '''''''''\n",
    "    this function apply several functions defined above.\n",
    "    It takes as input a numpy array.\n",
    "    It outputs a vector with the value of each function: mean, std, ...\n",
    "    '''''''''\n",
    "    return mean(x),std(x),ptp(x),var(x),minim(x),maxim(x),argminim(x),argmaxim(x),rms(x),skewness(x),kurtosis(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f34db4",
   "metadata": {},
   "source": [
    "# Import procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e839f3",
   "metadata": {},
   "source": [
    "## Lists initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c4a11a",
   "metadata": {},
   "source": [
    "Creation of useful lists and the final dataset initialization.\n",
    "\n",
    "The final dataset should has some columns related to information about the patient (Gender, Dominance hand, ID Number, Test, ...), 12 columns for each wave (for each wave we have mean, std, ... (in total 12 new features)). \n",
    "\n",
    "Since we tested each patient 4 times, the dimension of the final dataset will be:\n",
    "- number rows = 4 * number of patients = number of csv files\n",
    "- number columns = 12 * 5 (features * waves numbers) + fixed qualities (persona data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b079a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "waves = [\"Delta\", \"Theta\", \"Alpha\", \"Beta\", \"Gamma\"] # names of waves we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5917e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "dominance_list = []\n",
    "english_list = []\n",
    "gender_list = []\n",
    "participant_list = []\n",
    "\n",
    "# dictionary to store all the values for one dataframe\n",
    "final_dic = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb567f2",
   "metadata": {},
   "source": [
    "## Final dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7af30c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in all_filenames: # file 6 contains string number\n",
    "    \n",
    "    df = pd.read_csv(path + delimiter + name)\n",
    "\n",
    "    df = df.drop([\"Elements\"], axis=1)\n",
    "    df = df.dropna() # drop Nan values\n",
    "    df = df.reset_index(drop=True) # restart index\n",
    "    \n",
    "    # Add to lists the values related to patient profile\n",
    "    test_list.append(df[\"Test\"][0])\n",
    "    dominance_list.append(df[\"Dominance\"][0])\n",
    "    english_list.append(df[\"English\"][0])\n",
    "    gender_list.append(df[\"Gender\"][0])\n",
    "    participant_list.append(df[\"Participant\"][0])\n",
    "\n",
    "    # create empty list to collect mean, std, var, ... for a fixed wave\n",
    "    gen_features = {}\n",
    "    \n",
    "    #print(name)\n",
    "    \n",
    "    for wave in waves: # for each waves (ALpha, Beta, Gamma, Delta, Theta)\n",
    "        \n",
    "        # create empty list to collect all the data in the four columns for a fixed wave\n",
    "        all_values = []\n",
    "        \n",
    "        for col in df.columns: # for each column\n",
    "            if col.split(\"_\")[0] == wave: # if the wave is in the column name, then:\n",
    "                \n",
    "                # Marti code\n",
    "                # to clean data, we delete columns in which the values is equal to the one 4 time points before\n",
    "                for i in range(4,len(df[col])):\n",
    "                    if not df[col][i] == df[col][i-4]:\n",
    "                        all_values.append(df[col][i])\n",
    "                #if len(all_values)!=0: # if the values are not constant, we want to add also the first 4 values\n",
    "                #    for i in range(4):\n",
    "                #        all_values.append(df[col][i])\n",
    "                for i in range(4):\n",
    "                    all_values.append(df[col][i])  \n",
    "                    \n",
    "        # add a list with the new features associated to the name of the wave in a dictionary\n",
    "        gen_features[wave] = list( concatenate_features(np.array(all_values)) )\n",
    "    \n",
    "    final_dic[name] = gen_features\n",
    "         \n",
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d48a7aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>English</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Participant</th>\n",
       "      <th>Dominance</th>\n",
       "      <th>Delta_mean</th>\n",
       "      <th>Delta_std</th>\n",
       "      <th>Delta_ptp</th>\n",
       "      <th>Delta_var</th>\n",
       "      <th>Delta_minim</th>\n",
       "      <th>...</th>\n",
       "      <th>Gamma_std</th>\n",
       "      <th>Gamma_ptp</th>\n",
       "      <th>Gamma_var</th>\n",
       "      <th>Gamma_minim</th>\n",
       "      <th>Gamma_maxim</th>\n",
       "      <th>Gamma_argminim</th>\n",
       "      <th>Gamma_argmaxim</th>\n",
       "      <th>Gamma_rms</th>\n",
       "      <th>Gamma_skewness</th>\n",
       "      <th>Gamma_kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LHC</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Dominant</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LHC</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Dominant</td>\n",
       "      <td>0.526442</td>\n",
       "      <td>0.294538</td>\n",
       "      <td>1.336331</td>\n",
       "      <td>0.086752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424252</td>\n",
       "      <td>1.609542</td>\n",
       "      <td>0.179990</td>\n",
       "      <td>-0.325524</td>\n",
       "      <td>1.284018</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.589387</td>\n",
       "      <td>0.181548</td>\n",
       "      <td>-1.023259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RHS</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NonDominant</td>\n",
       "      <td>0.340579</td>\n",
       "      <td>0.413665</td>\n",
       "      <td>1.775144</td>\n",
       "      <td>0.171119</td>\n",
       "      <td>-0.550673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463500</td>\n",
       "      <td>1.632933</td>\n",
       "      <td>0.214832</td>\n",
       "      <td>-0.614941</td>\n",
       "      <td>1.017991</td>\n",
       "      <td>35.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.638468</td>\n",
       "      <td>-0.662233</td>\n",
       "      <td>-1.064268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RHS</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>139.0</td>\n",
       "      <td>Dominant</td>\n",
       "      <td>0.933517</td>\n",
       "      <td>0.513017</td>\n",
       "      <td>1.899951</td>\n",
       "      <td>0.263186</td>\n",
       "      <td>-0.091274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397164</td>\n",
       "      <td>1.218180</td>\n",
       "      <td>0.157739</td>\n",
       "      <td>-0.067039</td>\n",
       "      <td>1.151140</td>\n",
       "      <td>19.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.682415</td>\n",
       "      <td>-0.174877</td>\n",
       "      <td>-1.284745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LHC</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>106.0</td>\n",
       "      <td>NonDominant</td>\n",
       "      <td>0.567189</td>\n",
       "      <td>0.504123</td>\n",
       "      <td>2.265507</td>\n",
       "      <td>0.254140</td>\n",
       "      <td>-0.570804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630338</td>\n",
       "      <td>1.762350</td>\n",
       "      <td>0.397326</td>\n",
       "      <td>-0.568534</td>\n",
       "      <td>1.193816</td>\n",
       "      <td>47.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.761039</td>\n",
       "      <td>-0.310182</td>\n",
       "      <td>-1.689339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>RHS</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>322.0</td>\n",
       "      <td>NonDominant</td>\n",
       "      <td>0.582510</td>\n",
       "      <td>0.434822</td>\n",
       "      <td>1.406913</td>\n",
       "      <td>0.189070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339918</td>\n",
       "      <td>1.001319</td>\n",
       "      <td>0.115544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.001319</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.673433</td>\n",
       "      <td>-0.633925</td>\n",
       "      <td>-0.811194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>RHS</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>323.0</td>\n",
       "      <td>Dominant</td>\n",
       "      <td>0.504330</td>\n",
       "      <td>0.501552</td>\n",
       "      <td>1.719051</td>\n",
       "      <td>0.251554</td>\n",
       "      <td>-0.540604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473516</td>\n",
       "      <td>1.444715</td>\n",
       "      <td>0.224217</td>\n",
       "      <td>-0.550697</td>\n",
       "      <td>0.894018</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.494641</td>\n",
       "      <td>0.231307</td>\n",
       "      <td>-1.265068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>RHS</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>324.0</td>\n",
       "      <td>NonDominant</td>\n",
       "      <td>0.204568</td>\n",
       "      <td>0.381588</td>\n",
       "      <td>1.164488</td>\n",
       "      <td>0.145609</td>\n",
       "      <td>-0.190121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247382</td>\n",
       "      <td>0.789973</td>\n",
       "      <td>0.061198</td>\n",
       "      <td>-0.507092</td>\n",
       "      <td>0.282881</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.269017</td>\n",
       "      <td>0.040762</td>\n",
       "      <td>-1.022177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>RHS</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>325.0</td>\n",
       "      <td>Dominant</td>\n",
       "      <td>0.472270</td>\n",
       "      <td>0.334002</td>\n",
       "      <td>0.989795</td>\n",
       "      <td>0.111557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216456</td>\n",
       "      <td>0.577910</td>\n",
       "      <td>0.046853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.331766</td>\n",
       "      <td>0.118204</td>\n",
       "      <td>-1.506182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>RHS</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>326.0</td>\n",
       "      <td>Dominant</td>\n",
       "      <td>0.679960</td>\n",
       "      <td>0.580307</td>\n",
       "      <td>1.580237</td>\n",
       "      <td>0.336757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224479</td>\n",
       "      <td>0.745979</td>\n",
       "      <td>0.050391</td>\n",
       "      <td>-0.080289</td>\n",
       "      <td>0.665691</td>\n",
       "      <td>14.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.322786</td>\n",
       "      <td>0.660683</td>\n",
       "      <td>-0.666616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test English  Gender  Participant    Dominance  Delta_mean  Delta_std  \\\n",
       "0    LHC     Yes  Female        101.0     Dominant    0.000000   0.000000   \n",
       "1    LHC     Yes    Male        102.0     Dominant    0.526442   0.294538   \n",
       "2    RHS     Yes    Male        103.0  NonDominant    0.340579   0.413665   \n",
       "3    RHS     Yes    Male        139.0     Dominant    0.933517   0.513017   \n",
       "4    LHC     Yes    Male        106.0  NonDominant    0.567189   0.504123   \n",
       "..   ...     ...     ...          ...          ...         ...        ...   \n",
       "360  RHS     Yes    Male        322.0  NonDominant    0.582510   0.434822   \n",
       "361  RHS      No  Female        323.0     Dominant    0.504330   0.501552   \n",
       "362  RHS     Yes  Female        324.0  NonDominant    0.204568   0.381588   \n",
       "363  RHS     Yes  Female        325.0     Dominant    0.472270   0.334002   \n",
       "364  RHS     Yes    Male        326.0     Dominant    0.679960   0.580307   \n",
       "\n",
       "     Delta_ptp  Delta_var  Delta_minim  ...  Gamma_std  Gamma_ptp  Gamma_var  \\\n",
       "0     0.000000   0.000000     0.000000  ...   0.000000   0.000000   0.000000   \n",
       "1     1.336331   0.086752     0.000000  ...   0.424252   1.609542   0.179990   \n",
       "2     1.775144   0.171119    -0.550673  ...   0.463500   1.632933   0.214832   \n",
       "3     1.899951   0.263186    -0.091274  ...   0.397164   1.218180   0.157739   \n",
       "4     2.265507   0.254140    -0.570804  ...   0.630338   1.762350   0.397326   \n",
       "..         ...        ...          ...  ...        ...        ...        ...   \n",
       "360   1.406913   0.189070     0.000000  ...   0.339918   1.001319   0.115544   \n",
       "361   1.719051   0.251554    -0.540604  ...   0.473516   1.444715   0.224217   \n",
       "362   1.164488   0.145609    -0.190121  ...   0.247382   0.789973   0.061198   \n",
       "363   0.989795   0.111557     0.000000  ...   0.216456   0.577910   0.046853   \n",
       "364   1.580237   0.336757     0.000000  ...   0.224479   0.745979   0.050391   \n",
       "\n",
       "     Gamma_minim  Gamma_maxim  Gamma_argminim  Gamma_argmaxim  Gamma_rms  \\\n",
       "0       0.000000     0.000000             0.0             0.0   0.000000   \n",
       "1      -0.325524     1.284018            46.0            50.0   0.589387   \n",
       "2      -0.614941     1.017991            35.0           108.0   0.638468   \n",
       "3      -0.067039     1.151140            19.0            41.0   0.682415   \n",
       "4      -0.568534     1.193816            47.0            91.0   0.761039   \n",
       "..           ...          ...             ...             ...        ...   \n",
       "360     0.000000     1.001319            18.0            14.0   0.673433   \n",
       "361    -0.550697     0.894018            14.0            31.0   0.494641   \n",
       "362    -0.507092     0.282881             8.0            19.0   0.269017   \n",
       "363     0.000000     0.577910             0.0            17.0   0.331766   \n",
       "364    -0.080289     0.665691            14.0            28.0   0.322786   \n",
       "\n",
       "     Gamma_skewness  Gamma_kurtosis  \n",
       "0          0.000000       -3.000000  \n",
       "1          0.181548       -1.023259  \n",
       "2         -0.662233       -1.064268  \n",
       "3         -0.174877       -1.284745  \n",
       "4         -0.310182       -1.689339  \n",
       "..              ...             ...  \n",
       "360       -0.633925       -0.811194  \n",
       "361        0.231307       -1.265068  \n",
       "362        0.040762       -1.022177  \n",
       "363        0.118204       -1.506182  \n",
       "364        0.660683       -0.666616  \n",
       "\n",
       "[365 rows x 60 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an empty dataframe\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# assign to the column 'Test' of the final df all the values which are in the test_list\n",
    "final_df[\"Test\"] = test_list\n",
    "final_df[\"English\"] = english_list\n",
    "final_df[\"Gender\"] = gender_list\n",
    "final_df[\"Participant\"] = participant_list\n",
    "final_df[\"Dominance\"] = dominance_list\n",
    "\n",
    "\n",
    "functions = [\"mean\", \"std\", \"ptp\",\"var\",\"minim\",\"maxim\",\"argminim\",\"argmaxim\",\"rms\",\"skewness\",\"kurtosis\"] \n",
    "\n",
    "for i in range(len(all_filenames)): # i indicates the row (index for each file)\n",
    "    # Change the class from Left to Dominant or NonDominant\n",
    "    if final_df.at[i, \"Dominance\"] == 'Left':\n",
    "        if final_df.at[i, \"Test\"] =='LHC' or final_df.at[i, \"Test\"] =='LHS':\n",
    "            final_df.at[i, \"Dominance\"] = 'Dominant'\n",
    "        else:\n",
    "            final_df.at[i, \"Dominance\"] = 'NonDominant'\n",
    "    else: # change the class from Right to Dominant or NonDominant\n",
    "        if final_df.at[i, \"Test\"] =='RHC' or final_df.at[i, \"Test\"] =='RHS':\n",
    "            final_df.at[i, \"Dominance\"] = 'Dominant'\n",
    "        else:\n",
    "            final_df.at[i, \"Dominance\"] = 'NonDominant'\n",
    "    name = all_filenames[i]\n",
    "    \n",
    "    for wave in waves: # for each wave\n",
    "        for j in range(11): \n",
    "            # at row i, and column specified by the name of the wave and features\n",
    "            final_df.at[i, wave + \"_\" + functions[j]] = final_dic[name][wave][j]       \n",
    "            \n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b00a90",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a06245f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac5db22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1393f05a",
   "metadata": {},
   "source": [
    "# Pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f3b03",
   "metadata": {},
   "source": [
    "Check the type of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a4e3558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Test               object\n",
       "English            object\n",
       "Gender             object\n",
       "Participant       float64\n",
       "Dominance          object\n",
       "Delta_mean        float64\n",
       "Delta_std         float64\n",
       "Delta_ptp         float64\n",
       "Delta_var         float64\n",
       "Delta_minim       float64\n",
       "Delta_maxim       float64\n",
       "Delta_argminim    float64\n",
       "Delta_argmaxim    float64\n",
       "Delta_rms         float64\n",
       "Delta_skewness    float64\n",
       "Delta_kurtosis    float64\n",
       "Theta_mean        float64\n",
       "Theta_std         float64\n",
       "Theta_ptp         float64\n",
       "Theta_var         float64\n",
       "Theta_minim       float64\n",
       "Theta_maxim       float64\n",
       "Theta_argminim    float64\n",
       "Theta_argmaxim    float64\n",
       "Theta_rms         float64\n",
       "Theta_skewness    float64\n",
       "Theta_kurtosis    float64\n",
       "Alpha_mean        float64\n",
       "Alpha_std         float64\n",
       "Alpha_ptp         float64\n",
       "Alpha_var         float64\n",
       "Alpha_minim       float64\n",
       "Alpha_maxim       float64\n",
       "Alpha_argminim    float64\n",
       "Alpha_argmaxim    float64\n",
       "Alpha_rms         float64\n",
       "Alpha_skewness    float64\n",
       "Alpha_kurtosis    float64\n",
       "Beta_mean         float64\n",
       "Beta_std          float64\n",
       "Beta_ptp          float64\n",
       "Beta_var          float64\n",
       "Beta_minim        float64\n",
       "Beta_maxim        float64\n",
       "Beta_argminim     float64\n",
       "Beta_argmaxim     float64\n",
       "Beta_rms          float64\n",
       "Beta_skewness     float64\n",
       "Beta_kurtosis     float64\n",
       "Gamma_mean        float64\n",
       "Gamma_std         float64\n",
       "Gamma_ptp         float64\n",
       "Gamma_var         float64\n",
       "Gamma_minim       float64\n",
       "Gamma_maxim       float64\n",
       "Gamma_argminim    float64\n",
       "Gamma_argmaxim    float64\n",
       "Gamma_rms         float64\n",
       "Gamma_skewness    float64\n",
       "Gamma_kurtosis    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ae599",
   "metadata": {},
   "source": [
    "We notice that are all float, exept English, Dominance, Gender and Test. Thus, to use these variables in several algorithms it is necessary to encode them as numeric.\n",
    "\n",
    "Moreover we need to remember also that Participant is an id, and the value of this variable should not influence the result of the algorithm, so we are going to drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee41776",
   "metadata": {},
   "source": [
    "## Split in X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0f3a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = final_df[\"Dominance\"]\n",
    "X = final_df.drop([\"Dominance\", \"Participant\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c794b6",
   "metadata": {},
   "source": [
    "## Encoding indipendent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12be16bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>English</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LHC</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LHC</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RHS</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RHS</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LHC</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test English  Gender\n",
       "0  LHC     Yes  Female\n",
       "1  LHC     Yes    Male\n",
       "2  RHS     Yes    Male\n",
       "3  RHS     Yes    Male\n",
       "4  LHC     Yes    Male"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_df = X.select_dtypes(include=['object']).copy()\n",
    "obj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0771aab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>English</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Delta_mean</th>\n",
       "      <th>Delta_std</th>\n",
       "      <th>Delta_ptp</th>\n",
       "      <th>Delta_var</th>\n",
       "      <th>Delta_minim</th>\n",
       "      <th>Delta_maxim</th>\n",
       "      <th>Delta_argminim</th>\n",
       "      <th>...</th>\n",
       "      <th>Gamma_std</th>\n",
       "      <th>Gamma_ptp</th>\n",
       "      <th>Gamma_var</th>\n",
       "      <th>Gamma_minim</th>\n",
       "      <th>Gamma_maxim</th>\n",
       "      <th>Gamma_argminim</th>\n",
       "      <th>Gamma_argmaxim</th>\n",
       "      <th>Gamma_rms</th>\n",
       "      <th>Gamma_skewness</th>\n",
       "      <th>Gamma_kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526442</td>\n",
       "      <td>0.294538</td>\n",
       "      <td>1.336331</td>\n",
       "      <td>0.086752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.336331</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424252</td>\n",
       "      <td>1.609542</td>\n",
       "      <td>0.179990</td>\n",
       "      <td>-0.325524</td>\n",
       "      <td>1.284018</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.589387</td>\n",
       "      <td>0.181548</td>\n",
       "      <td>-1.023259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.340579</td>\n",
       "      <td>0.413665</td>\n",
       "      <td>1.775144</td>\n",
       "      <td>0.171119</td>\n",
       "      <td>-0.550673</td>\n",
       "      <td>1.224472</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463500</td>\n",
       "      <td>1.632933</td>\n",
       "      <td>0.214832</td>\n",
       "      <td>-0.614941</td>\n",
       "      <td>1.017991</td>\n",
       "      <td>35.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.638468</td>\n",
       "      <td>-0.662233</td>\n",
       "      <td>-1.064268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933517</td>\n",
       "      <td>0.513017</td>\n",
       "      <td>1.899951</td>\n",
       "      <td>0.263186</td>\n",
       "      <td>-0.091274</td>\n",
       "      <td>1.808677</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397164</td>\n",
       "      <td>1.218180</td>\n",
       "      <td>0.157739</td>\n",
       "      <td>-0.067039</td>\n",
       "      <td>1.151140</td>\n",
       "      <td>19.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.682415</td>\n",
       "      <td>-0.174877</td>\n",
       "      <td>-1.284745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.567189</td>\n",
       "      <td>0.504123</td>\n",
       "      <td>2.265507</td>\n",
       "      <td>0.254140</td>\n",
       "      <td>-0.570804</td>\n",
       "      <td>1.694703</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630338</td>\n",
       "      <td>1.762350</td>\n",
       "      <td>0.397326</td>\n",
       "      <td>-0.568534</td>\n",
       "      <td>1.193816</td>\n",
       "      <td>47.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.761039</td>\n",
       "      <td>-0.310182</td>\n",
       "      <td>-1.689339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Test  English  Gender  Delta_mean  Delta_std  Delta_ptp  Delta_var  \\\n",
       "0     0        1       0    0.000000   0.000000   0.000000   0.000000   \n",
       "1     0        1       1    0.526442   0.294538   1.336331   0.086752   \n",
       "2     3        1       1    0.340579   0.413665   1.775144   0.171119   \n",
       "3     3        1       1    0.933517   0.513017   1.899951   0.263186   \n",
       "4     0        1       1    0.567189   0.504123   2.265507   0.254140   \n",
       "\n",
       "   Delta_minim  Delta_maxim  Delta_argminim  ...  Gamma_std  Gamma_ptp  \\\n",
       "0     0.000000     0.000000             0.0  ...   0.000000   0.000000   \n",
       "1     0.000000     1.336331            22.0  ...   0.424252   1.609542   \n",
       "2    -0.550673     1.224472            56.0  ...   0.463500   1.632933   \n",
       "3    -0.091274     1.808677            47.0  ...   0.397164   1.218180   \n",
       "4    -0.570804     1.694703            50.0  ...   0.630338   1.762350   \n",
       "\n",
       "   Gamma_var  Gamma_minim  Gamma_maxim  Gamma_argminim  Gamma_argmaxim  \\\n",
       "0   0.000000     0.000000     0.000000             0.0             0.0   \n",
       "1   0.179990    -0.325524     1.284018            46.0            50.0   \n",
       "2   0.214832    -0.614941     1.017991            35.0           108.0   \n",
       "3   0.157739    -0.067039     1.151140            19.0            41.0   \n",
       "4   0.397326    -0.568534     1.193816            47.0            91.0   \n",
       "\n",
       "   Gamma_rms  Gamma_skewness  Gamma_kurtosis  \n",
       "0   0.000000        0.000000       -3.000000  \n",
       "1   0.589387        0.181548       -1.023259  \n",
       "2   0.638468       -0.662233       -1.064268  \n",
       "3   0.682415       -0.174877       -1.284745  \n",
       "4   0.761039       -0.310182       -1.689339  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in obj_df.columns:\n",
    "    X[col] = obj_df[col].astype('category').cat.codes\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9eb0d",
   "metadata": {},
   "source": [
    "## Split in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74300c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is: (292, 58)\n",
      "The shape of X_test is: (73, 58)\n",
      "\n",
      "The shape of y_train is: (292,)\n",
      "The shape of y_test is: (73,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42)\n",
    "\n",
    "print(\"The shape of X_train is:\", X_train.shape)\n",
    "print(\"The shape of X_test is:\", X_test.shape)\n",
    "print('')\n",
    "print(\"The shape of y_train is:\", y_train.shape)\n",
    "print(\"The shape of y_test is:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccf59a1",
   "metadata": {},
   "source": [
    "## Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c519cf68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For label data (y) always use LabelEncoder\n",
    "LaEnc = LabelEncoder()\n",
    "y_train = LaEnc.fit_transform(y_train)\n",
    "y_train\n",
    "\n",
    "y_test = LaEnc.transform(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0f537b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b5fc3d",
   "metadata": {},
   "source": [
    "# Classification analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ce4bd8",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50939451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[29  8]\n",
      " [13 23]]\n",
      "\n",
      "\n",
      "Accuracy of KNN: 71.23287671232876 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "KNNclassifier = KNeighborsClassifier(n_neighbors = 3, metric = 'euclidean', p = 2)\n",
    "KNNclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = KNNclassifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of KNN:\", acc*100,'\\n')\n",
    "\n",
    "KNNacc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409aa2f9",
   "metadata": {},
   "source": [
    "## SVM linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1434964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[28  9]\n",
      " [ 7 29]]\n",
      "\n",
      "\n",
      "Accuracy of SVM linear: 78.08219178082192 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVMclassifier = SVC(kernel = 'linear', random_state = 1)\n",
    "SVMclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = SVMclassifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of SVM linear:\", acc*100,'\\n')\n",
    "\n",
    "linearSVMacc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a89746",
   "metadata": {},
   "source": [
    "## SVM non linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f443d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[29  8]\n",
      " [11 25]]\n",
      "\n",
      "\n",
      "Accuracy of SVM rbf: 73.97260273972603 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVMclassifier = SVC(kernel = 'rbf', random_state = 1)\n",
    "SVMclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = SVMclassifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of SVM rbf:\", acc*100,'\\n')\n",
    "\n",
    "nonlinearSVMacc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64e223a",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "febbf654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[32  5]\n",
      " [18 18]]\n",
      "\n",
      "\n",
      "Accuracy of Naive bayes Classifier: 68.4931506849315 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "NBclassifier = GaussianNB()\n",
    "NBclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = NBclassifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of Naive bayes Classifier:\", acc*100,'\\n')\n",
    "\n",
    "NBacc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc7416",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f8921c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[29  8]\n",
      " [11 25]]\n",
      "\n",
      "\n",
      "Accuracy of random forest: 73.97260273972603 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Forestclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 1)\n",
    "Forestclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = Forestclassifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of random forest:\", acc*100,'\\n')\n",
    "\n",
    "Forestacc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255ae26",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49f7c838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[28  9]\n",
      " [ 6 30]]\n",
      "\n",
      "\n",
      "Accuracy of decision tree: 79.45205479452055 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "DecisionTreeclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "DecisionTreeclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = DecisionTreeclassifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of decision tree:\", acc*100,'\\n')\n",
    "\n",
    "Decisionacc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9326d6d4",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63840819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[30  7]\n",
      " [ 7 29]]\n",
      "\n",
      "\n",
      "Accuracy of decision tree: 80.82191780821918 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "LRclassifier = LogisticRegression()\n",
    "LRclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LRclassifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of logistic regression classifier:\", acc*100,'\\n')\n",
    "\n",
    "LRacc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eafa4b5",
   "metadata": {},
   "source": [
    "## LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "846eba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lassoclassifier=Lasso(alpha=0.5)\n",
    "Lassoclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = Lassoclassifier.predict(X_test)\n",
    "\n",
    "#cm = confusion_matrix(y_test, y_pred)\n",
    "#acc = accuracy_score(y_test, y_pred)\n",
    "#print('Confusion Matrix')\n",
    "#print(cm)\n",
    "#print(\"\\n\")\n",
    "#print(\"Accuracy of Lasso:\", acc*100,'\\n')\n",
    "\n",
    "#LASSOacc = acc\n",
    "\n",
    "\n",
    "#I am not sure how to use this regression model for classification\n",
    "    #in researching it, I also came upon ridge regression, but I \n",
    "    #didn't look further into it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133175a7",
   "metadata": {},
   "source": [
    "## Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "604899a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of KNN: 71.23\n",
      "Accuracy of SVM linear: 78.08\n",
      "Accuracy of SVM rbf: 73.97\n",
      "Accuracy of Naive bayes Classifier: 68.49\n",
      "Accuracy of random forest: 73.97\n",
      "Accuracy of decision tree: 79.45\n",
      "Accuracy of logistic regression: 80.82\n"
     ]
    }
   ],
   "source": [
    "print('\\n'\"Accuracy of KNN:\", format(KNNacc*100, '.2f'))\n",
    "print(\"Accuracy of SVM linear:\", format(linearSVMacc*100, '.2f'))\n",
    "print(\"Accuracy of SVM rbf:\", format(nonlinearSVMacc*100, '.2f'))\n",
    "print(\"Accuracy of Naive bayes Classifier:\", format(NBacc*100, '.2f'))\n",
    "print(\"Accuracy of random forest:\", format(Forestacc*100, '.2f'))\n",
    "print(\"Accuracy of decision tree:\", format(Decisionacc*100, '.2f'))\n",
    "print(\"Accuracy of logistic regression:\", format(LRacc*100, '.2f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba40961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
